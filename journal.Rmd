---
title: "Data Science for Managers: My Coding Journal"
author: "Shawn Murray"
date: "14/06/2020"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

<style>
.list-group-item.active, .list-group-item.active:focus, .list-group-item.active:hover {
    background-color: #2DC6D6;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

<!-- IMPORTANT: You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing. -->


<!-- This is an .Rmd file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a \# in front of your text, it will create a top level-header. -->

# My first post

2020 | 6 | 14 Last compiled: `r Sys.Date()`

This is my first post. 

## Second level header

You can add more headers by adding more hashtags. These won't be put into the table of contents

### third level header

Here's an even lower level header

# My second post (note the order)

2018 | 7 | 23 Last compiled: `r Sys.Date()`

I'm writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom

# Adding R stuff

So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the sam place. 

So, let's say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation =1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:

```{r}
samples <- rnorm(100, mean=0, sd=1)
hist(samples)
```

When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag), from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You learn all of these things and more can be customized in each R code block.

# The big idea

Use this lab journal to record what you do in R. This way I will be able to see what you are doing and help you along the way. You will also be creating a repository of all the things you do. You can make posts about everything. Learning specific things in R (project unrelated), and doing things for the project that we will discuss at the beginning of the Fall semester. You can get started now by fiddling around with googling things, and trying stuff out in R. I've placed some helpful starting links in the links page on this website

# What can you do right now by yourself?

It's hard to learn programming when you don't have specific problems that you are trying to solve. Everything just seems abstract.

I wrote an [introductory programming book that introduces R](https://crumplab.github.io/programmingforpsych/), and gives some [concrete problems for you to solve](https://crumplab.github.io/programmingforpsych/programming-challenges-i-learning-the-fundamentals.html). 

To get the hang of journaling and solving the problems to learn programming, my suggestion is that you use this .Rmd file to solve the problems. It would look like this:

# Problem 1

Do simple math with numbers, addition, subtraction, multiplication, division

```{r}
1+2
2*5
5/3
(1+6+4)/5

```

# Problem 2

Put numbers into variables, do simple math on the variables

```{r}
a<-1
b<-2
a+b

d<-c(1,2,3)
e<-c(5,6,7)
d+e
d*e
d/e

```

# Problem 3

Write code that will place the numbers 1 to 100 separately into a variable using for loop. Then, again using the seq function.

```{r}
# for loop solution
# i becomes the number 1 to 100 at each step of the loop


a <- length(100) # make empty variable, set length to 100
for (i in 1:100){
  a[i] <-i #assigns the number in i, to the ith index of a
}

print(a)

# for loop solution #2

a<-c() #create empty variable using combine command
for (i in 1:100){
  a<-c(a,i) # keeps combining a with itself and the new number in i
}
print(a)

# seq solution
a <- seq(1,100,1) # look up help for seq using ?seq() in console
print(a)

```

# Problem 4

Find the sum of all the integer numbers from 1 to 100.

```{r}
# Using sum function sum()
a = 1:100
b = sum(a)
print(b)

# Using a loop

c <- length(100) # make empty variable, set length to 100
for (i in 1:100){
  c[i]<-i #assigns the number in i, to the ith index of a
}
sum(c)


```
# Intro to the tidyverse - Coding Challenge 1A

Analyzed sales by state using the data set from Brazilian Online shopping company.

```{r}

# SALES BY STATE ANALYSIS ----

# 1.0 Load libraries ----
library(tidyverse)


# 2.0 Importing Files ----

sellers_tbl <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_sellers_dataset.csv") 
order_items_tbl <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_order_items_dataset.csv")
orders_tbl      <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_orders_dataset.csv")


# 3.0 Examining Data ----

# 4.0 Joining Data ----

sellers_joined_tbl  <- order_items_tbl %>%
  left_join(orders_tbl) %>%
  left_join(sellers_tbl)

# 5.0 Wrangling Data ----

sellers_wrangled_tbl <- sellers_joined_tbl %>%
  
  separate(col    = seller.location,
           into   = c("seller.city", "seller.state"),
           sep    = ", ",
           remove = FALSE) %>%
  
  mutate(total.price = price + freight.value) %>%
  
  select(-starts_with("product.")) %>%
  
  select(-ends_with(".date")) %>%
  
  
  rename(order_date = order.purchase.timestamp) %>% 
  
  set_names(names(.) %>% 
              
              str_replace_all("\\.", "_"))

# 6.0 Business Insights ----

library(lubridate)

# 6.1 Sales by Year and Category 2 ----

# Step 1 - Manipulate

revenue_by_year_and_state_tbl <- sellers_wrangled_tbl %>%
  
  # Select columns and add a year
  select(order_date, total_price, seller_city, seller_state) %>% 
  mutate(year = year(order_date)) %>%
  
  # Filter  > 1.000.000
  group_by(seller_state) %>% 
  filter(sum(total_price) > 1000000) %>% # If you run the code up here, R will tell you that we have 6 groups
  ungroup() %>%
  
  # Group by and summarize year and main catgegory
  group_by(year, seller_state) %>% 
  summarise(revenue = sum(total_price)) %>% 
  ungroup() %>%
  
  # Format $ Text
  mutate(revenue_text = scales::dollar(revenue))

revenue_by_year_and_state_tbl 


# Step 2 - Visualize
revenue_by_year_and_state_tbl  %>%
  
  # Set up x, y, fill
  ggplot(aes(x = year, y = revenue, fill = seller_state)) +
  
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  
  # Facet
  facet_wrap(~ seller_state) +
  
  # Formatting
  scale_y_continuous(labels = scales::dollar) +
  labs(
    title = "Revenue by year and state",
    subtitle = "SP had the largest portion of revenues",
    fill = "State" # Changes the legend name
  )

# 7.0 Writing Files ----

library(fs)
fs::dir_create("Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student")

# 7.1 Excel ----

library("writexl")
write_xlsx( sellers_wrangled_tbl, "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/sellers_table.xlsx")
write_xlsx(revenue_by_year_and_state_tbl, "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/revenue_by_year_and_state.xlsx")

# 7.2 CSV ----

write_csv( sellers_wrangled_tbl, "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/sellers_table.csv")
write_csv( revenue_by_year_and_state_tbl , "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/revenue_by_year_and_state.csv")

# 7.3 RDS ----
write_rds( sellers_wrangled_tbl, "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/sellers_table.rds")
write_rds( revenue_by_year_and_state_tbl , "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/revenue_by_year_and_state.rds")
```

# Intro to the tidyverse - Coding Challenge 1B

Used the English translation of the categories and intergrated it back into the example code that was provided.

```{r}

# SALES ANALYSIS WITH ENGLISH TRANSLATION ----

# 1.0 Load libraries ----
library(tidyverse)
library(readxl)


# 2.0 Importing Files ----
# A good convention is to use the csv file name and suffix it with tbl for the data structure tibble
order_items_tbl <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_order_items_dataset.csv") 
products_tbl    <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_products_dataset.csv")
orders_tbl      <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_orders_dataset.csv")
product_cat_name_english  <- read_excel("Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/product_category_name_translation.xlsx")

# 3.0 Fixing name on new table ----
prod_cat_name_eng_corrected <- product_cat_name_english %>%
  
  set_names(names(.) %>% 
              
              str_replace_all("_", "\\."))

prod_cat_name_eng_corrected

# 4.0 Joining Data ----

order_items_joined_tbl  <- order_items_tbl %>%
  left_join(orders_tbl) %>%
  left_join(products_tbl)%>%
  left_join(prod_cat_name_eng_corrected)

# 5.0 Wrangling Data ----

order_items_wrangled_tbl <- order_items_joined_tbl %>%
  
  separate(col    = product.category.name.english,
           into   = c("main.category.name", "sub.category.name"),
           sep    = " - ",
           remove = FALSE) %>%
  
  mutate(total.price = price + freight.value) %>%
  
  select(-starts_with("product.")) %>%
  
  select(-ends_with(".date")) %>%
  
  bind_cols(order_items_joined_tbl %>% select(product.id)) %>% 
  
  select(contains("timestamp"), contains(".id"),
         main.category.name, sub.category.name, price, freight.value, total.price,
         everything()) %>% 
  
  rename(order_date = order.purchase.timestamp) %>% 
  
  set_names(names(.) %>% 
              
              str_replace_all("\\.", "_"))

# 6.0 Business Insights ----
# 6.1 Sales by Year ----
library(lubridate)
# Step 1 - Manipulate

# Create a table revenue_by_year_tbl

revenue_by_year_tbl <- order_items_wrangled_tbl %>%
  
  # Select Columns
  select(order_date, total_price) %>%
  
  # add column with year by using mutate and extracting the year from order date
  mutate(year =year(order_date)) %>%
  
  # Grouping by year and summarizing sales
  group_by(year) %>% 
  summarize(revenue = sum(total_price)) %>%
  
  # Optional: Add a column that turns the numbers into a currency format (makes it in the plot optically more appealing)
  mutate(revenue_text = scales::dollar(revenue, prefix = "$"))

revenue_by_year_tbl

# Step 2 - Visualize


revenue_by_year_tbl %>%
  
  # Setup canvas with the columns year (x-axis) and revenue (y-axis)
  ggplot(aes(x = year, y = revenue)) +
  
  # Geometries
  geom_col(fill = "#2DC6D6") + # Use geom_col for a bar plot
  geom_label(aes(label = revenue_text)) + # Adding labels to the bars
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline
  
  # Formatting
  scale_y_continuous(labels = scales::dollar) + # Change the y-axis
  labs(
    title    = "Revenue by year",
    subtitle = "Upward Trend",
    x = "", # Override defaults for x and y
    y = "Revenue"
  )
# 6.2 Sales by Year and Category 2 ----

# Step 1 - Manipulate

revenue_by_year_cat_main_tbl <- order_items_wrangled_tbl %>%
  
  # Select columns and add a year
  select(order_date, total_price, main_category_name) %>% 
  mutate(year = year(order_date)) %>%
  
  # Filter  > 1.000.000
  group_by(main_category_name) %>% 
  filter(sum(total_price) > 1000000) %>% # If you run the code up here, R will tell you that we have 6 groups
  ungroup() %>%
  
  # Group by and summarize year and main catgegory
  group_by(year, main_category_name) %>% 
  summarise(revenue = sum(total_price)) %>% 
  ungroup() %>%
  
  # Format $ Text
  mutate(revenue_text = scales::dollar(revenue))

revenue_by_year_cat_main_tbl  


# Step 2 - Visualize
revenue_by_year_cat_main_tbl %>%
  
  # Set up x, y, fill
  ggplot(aes(x = year, y = revenue, fill = main_category_name)) +
  
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  
  # Facet
  facet_wrap(~ main_category_name) +
  
  # Formatting
  scale_y_continuous(labels = scales::dollar) +
  labs(
    title = "Revenue by year and main category",
    subtitle = "Each product category has an upward trend",
    fill = "Main category" # Changes the legend name
  )


# 7.0 Writing Files ----
# If you want to interact with the filesystem use the fs package

library(fs)
fs::dir_create("Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student")

# 7.1 Excel ----

library("writexl")
write_xlsx( order_items_wrangled_tbl, "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/order_items_english.xlsx")

# 7.2 CSV ----
write_csv( order_items_wrangled_tbl, "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/order_items_english.csv")

# 7.3 RDS ----
write_rds( order_items_wrangled_tbl, "Rstudio/DS_business_case_01/00_data/01_e-commerce/04_wrangled_data_student/order_items_english.rds")

```

# Data Aquisition - Challenge 1 - Gather Data From a API

In this example we will gather a random cocktail from the cocktail DB and present information about it and how to make it.


```{r}
library(httr)
library(jsonlite)
library(tidyverse)
library(dplyr)

#Script to pull a random cocktail from the cocktail db.

resp <- GET("https://www.thecocktaildb.com/api/json/v1/1/random.php")
resp

random_drink = fromJSON(rawToChar(resp$content))

pullout_data <- random_drink[[1]] 

#Code to reduce number of columns and also filter out NA columns
your_random_drink <- as_tibble(pullout_data) %>% 
  select(strDrink ,strAlcoholic, strInstructions,strGlass, 
         strIngredient1:strIngredient7, strMeasure1:strMeasure7) %>% select_if(~sum(!is.na(.)) > 0)

print(your_random_drink)
print("Enjoy!!")


```

# Data Aquisition - Challenge 2 - Scrape Data from ecommerce site

In this example we will scrape data from a amazon search result about gaming pc's.


```{r}

library(tidyverse) # Main Package - Loads dplyr, purrr
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(httr)

url_home          <- "https://www.amazon.de/s?k=gaming+pc&rh=n%3A427954031&ref=nb_sb_noss"
# Read in the HTML for the entire webpage
html_home         <- read_html(url_home)

# Web scrape the ids for the families
Name_items <- html_home %>%
  
  html_nodes(css = ".a-size-medium") %>%
  
 html_text()

Item_price <- html_home %>%
  
  html_nodes(css = ".a-price-whole") %>%
  
  html_text()  

Gaming_pc_tbl <- tibble(Name_items, Item_price)


```

# Data Wrangling (no code saved here as it really takes to long to run on my computer, please reach out if you want to see my code and I will send it to you)

Download and play with the patents data base to answer the following Questions:

Patent Dominance: What US company has the most patents? List the 10 US companies with the most aaigned/granted patents.
Recent patent acitivity: What US company had the most patents granted in 2019? List the top 10 companies with the most new granted patents for 2019.
Innovation in Tech: What is the most innovative tech sector? For the top 10 companies with the most patents, what are the top 5 USPTO tech main classes?


# Data Visualization

Create at least 2 plots.

For the first one use the olist data and create a violin plot that shows the price distribution for whatever categories you choose.

Take the covid data from the last session and map the death / cases over the time. Show the trend for the entire world as well as for Germany and the USA (line plot).

Optional: Create a worldmap and color the countries according to the fatality (total deaths per capita). If it is easier for you, you can do it also just for the states of the USA or any other state (you need to get a different dataset though).

```{r}
#part 1

# SALES ANALYSIS WITH ENGLISH TRANSLATION ----

# 1.0 Load libraries ----
library(tidyverse)
library(readxl)


# 2.0 Importing Files ----
# A good convention is to use the csv file name and suffix it with tbl for the data structure tibble
order_items_tbl <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_order_items_dataset.csv") 
products_tbl    <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_products_dataset.csv")
orders_tbl      <- read_csv(file = "Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/olist_orders_dataset.csv")
product_cat_name_english  <- read_excel("Rstudio/DS_business_case_01/00_data/01_e-commerce/01_raw_data/product_category_name_translation.xlsx")

# 3.0 Fixing name on new table ----
prod_cat_name_eng_corrected <- product_cat_name_english %>%
  
  set_names(names(.) %>% 
              
              str_replace_all("_", "\\."))

prod_cat_name_eng_corrected

# 4.0 Joining Data ----

order_items_joined_tbl  <- order_items_tbl %>%
  left_join(orders_tbl) %>%
  left_join(products_tbl)%>%
  left_join(prod_cat_name_eng_corrected)

# 5.0 Wrangling Data ----

order_items_wrangled_tbl <- order_items_joined_tbl %>%
  
  separate(col    = product.category.name.english,
           into   = c("main.category.name", "sub.category.name"),
           sep    = " - ",
           remove = FALSE) %>%
  
  mutate(total.price = price + freight.value) %>%
  
  select(-starts_with("product.")) %>%
  
  select(-ends_with(".date")) %>%
  
  bind_cols(order_items_joined_tbl %>% select(product.id)) %>% 
  
  select(contains("timestamp"), contains(".id"),
         main.category.name, sub.category.name, price, freight.value, total.price,
         everything()) %>% 
  
  rename(order_date = order.purchase.timestamp) %>% 
  
  set_names(names(.) %>% 
              
              str_replace_all("\\.", "_"))

# 6.0 Business Insights ----
# 6.1 Sales by Year ----
library(lubridate)
# Step 1 - Manipulate

# Create a table revenue_by_year_tbl

revenue_by_year_tbl <- order_items_wrangled_tbl %>%
  
  # Select Columns
  select(order_date, total_price) %>%
  
  # add column with year by using mutate and extracting the year from order date
  mutate(year =year(order_date)) %>%
  
  # Grouping by year and summarizing sales
  group_by(year) %>% 
  summarize(revenue = sum(total_price)) %>%
  
  # Optional: Add a column that turns the numbers into a currency format (makes it in the plot optically more appealing)
  mutate(revenue_text = scales::dollar(revenue, prefix = "$"))

revenue_by_year_tbl

# Step 2 - Visualize


revenue_by_year_tbl %>%
  
  # Setup canvas with the columns year (x-axis) and revenue (y-axis)
  ggplot(aes(x = year, y = revenue)) +
  
  # Geometries
  geom_col(fill = "#2DC6D6") + # Use geom_col for a bar plot
  geom_label(aes(label = revenue_text)) + # Adding labels to the bars
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline
  
  # Formatting
  scale_y_continuous(labels = scales::dollar) + # Change the y-axis
  labs(
    title    = "Revenue by year",
    subtitle = "Upward Trend",
    x = "", # Override defaults for x and y
    y = "Revenue"
  )
# 6.2 Sales by Year and Category 2 ----

# Step 1 - Manipulate

revenue_by_year_cat_main_tbl <- order_items_wrangled_tbl %>%
  
  # Select columns and add a year
  select(order_date, total_price, main_category_name) %>% 
  mutate(year = year(order_date)) %>%
  
  # Filter  > 1.000.000
  group_by(main_category_name) %>% 
  filter(sum(total_price) > 1000000) %>% # If you run the code up here, R will tell you that we have 6 groups
  ungroup() %>%
  
  # Group by and summarize year and main catgegory
  group_by(year, main_category_name) %>% 
  summarise(revenue = sum(total_price)) %>% 
  ungroup() %>%
  
  # Format $ Text
  mutate(revenue_text = scales::dollar(revenue))

revenue_by_year_cat_main_tbl  


# Step 2 - Visualize
revenue_by_year_cat_main_tbl %>%
  
  # Set up x, y, fill
  ggplot(aes(x = year, y = revenue, fill = main_category_name)) +
  
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  
  # Facet
  facet_wrap(~ main_category_name) +
  
  # Formatting
  scale_y_continuous(labels = scales::dollar) +
  labs(
    title = "Revenue by year and main category",
    subtitle = "Each product category has an upward trend",
    fill = "Main category" # Changes the legend name
  )

# 6.3 Violin chart of price by category

# Step 1 - Manipulate

price_by_year_cat_main_tbl <- order_items_wrangled_tbl %>%
  
  # Select columns and add a year
  select(order_date, total_price, main_category_name) %>% 
  mutate(year = year(order_date)) %>%
  

# Filter  (choose a category)
group_by(main_category_name) %>% 
  filter(main_category_name %in% c("health_beauty","sports_leisure","bed_bath_table","furniture")) %>% # If you run the code up here, R will tell you that we have 6 groups
  ungroup()


# Step 2 - Visualize
price_by_year_cat_main_tbl %>%
  
  # Set up x, y, fill
  ggplot(aes(x = main_category_name , y = total_price)) +
  
  # Geometries
  geom_violin(draw_quantiles = c(0.25,0.5,0.75)) + # Run up to here to get a stacked bar plot
  
  # limits
  ylim(0,4000) +
 
  
  # Formatting
  
  labs(
    title = "Price by Category (no limit on Y axis)",
    subtitle = "Violin showing variability in price",
    fill = "Main category" # Changes the legend name
  )

# Step 2 - Visualize
price_by_year_cat_main_tbl %>%
  
  # Set up x, y, fill
  ggplot(aes(x = main_category_name , y = total_price)) +
  
  # Geometries
  geom_violin(draw_quantiles = c(0.25,0.5,0.75)) + # Run up to here to get a stacked bar plot
  
  # limits
  ylim(0,2000) +
  
  
  # Formatting
  
  labs(
    title = "Price by Category (Y limited to $2000)",
    subtitle = "Violin showing variability in price",
    fill = "Main category" # Changes the legend name
  )

# Step 2 - Visualize
price_by_year_cat_main_tbl %>%
  
  # Set up x, y, fill
  ggplot(aes(x = main_category_name , y = total_price)) +
  
  # Geometries
  geom_violin(draw_quantiles = c(0.25,0.5,0.75)) + # Run up to here to get a stacked bar plot
  
  # limits
  ylim(0,500) +
  
  
  # Formatting
  
  labs(
    title = "Price by Category (y axis limited to $500)",
    subtitle = "Violin showing variability in price",
    fill = "Main category" # Changes the legend name
  )

#part 2

# TASK Take the covid data from the last session and map the death / 
# cases over the time. Show the trend for the entire world as well as for Germany and the USA
#LINE PLOT

library(Quandl)
library(lubridate)
library(tidyverse)
library(readxl)
library(dplyr)
library(data.table)
url <- "https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"
covid_data_dt <- fread(url)

class(covid_data_dt)

# Create a table with data we need
#First graph is for Cumulative Cases


Relevant_data_needed<- covid_data_dt %>%
  
  # Select Columns
  select(dateRep, countriesAndTerritories, deaths, cases, popData2019) %>%
 group_by(countriesAndTerritories)%>%
  mutate(dateRep = as.Date(dateRep, "%d/%m/%Y")) %>%
  
 
  arrange(dateRep) %>%
  
  # Filter  (choose a country/countries)
  group_by(countriesAndTerritories) %>% 
  filter(countriesAndTerritories %in% c("Germany","United_States_of_America")) %>% 
  ungroup() %>%

group_by(countriesAndTerritories) %>% mutate(cumCases = cumsum(cases))

frmLast <- Relevant_data_needed %>%
  slice(which.max(dateRep))

frmFirst <- Relevant_data_needed %>% 
  slice(which.min(dateRep))


# Step 2 - Visualize Cases
Relevant_data_needed %>%
  
  # Set up x, y, fill
  ggplot(aes(x = dateRep, y = cumCases, group = countriesAndTerritories)) +
  
  # Geometries
  geom_line(aes(color=countriesAndTerritories)) + 
  
  scale_y_continuous(trans = 'log10') +
annotation_logticks(sides="lr") +
  scale_x_date(date_minor_breaks = "30 day")+
  geom_text(data = frmLast, aes(x = dateRep, y = cumCases, label = cumCases),size = 4, vjust = 2.5, hjust= 1)+
  geom_point(data = frmLast, aes(x = dateRep, y = cumCases), col = "Black", shape = 20, fill = "white", size = 2, stroke = 1.7)+
  labs( title = "COVID Cumulative Cases Germany Vs. USA")

# Create a table with data we need
#Second graph is for Cumulative deaths


# Relevant_data_needed<- covid_data_dt %>%
#   
#   # Select Columns
#   select(dateRep, countriesAndTerritories, deaths, cases, popData2019) %>%
#   group_by(countriesAndTerritories)%>%
#   mutate(dateRep = as.Date(dateRep, "%d/%m/%Y")) %>%
#   
#   
#   arrange(dateRep) %>%
#   
#   # Filter  (choose a country/countries)
#   group_by(countriesAndTerritories) %>% 
#   filter(countriesAndTerritories %in% c("Germany","United_States_of_America")) %>% 
#   ungroup() %>%
  
 Deaths_Relevant_data_needed<- Relevant_data_needed %>% 
   group_by(countriesAndTerritories) %>% 
   mutate(cumDeaths = cumsum(deaths))

frmLast <- Deaths_Relevant_data_needed %>% #last data date
  slice(which.max(dateRep))

frmFirst <- Deaths_Relevant_data_needed %>% #first data date 
  slice(which.min(dateRep))


# Step 2 - Visualize Cases
Deaths_Relevant_data_needed %>%
  
  # Set up x, y, fill
  ggplot(aes(x = dateRep, y = cumDeaths, group = countriesAndTerritories)) +
  
  # Geometries
  geom_line(aes(color=countriesAndTerritories)) + 
  
  scale_y_continuous(trans = 'log10') +
  annotation_logticks(sides="lr") +
  scale_x_date(date_minor_breaks = "15 day")+
  geom_text(data = frmLast, aes(x = dateRep, y = cumDeaths, label = cumDeaths),size = 4, vjust = 2.5, hjust= 1)+
  geom_point(data = frmLast, aes(x = dateRep, y = cumDeaths), col = "Black", shape = 20, fill = "white", size = 2, stroke = 1.7)+
  labs( title = "COVID Cumulative Deaths Germany Vs. USA")

#part 3
library("ggplot2")
theme_set(theme_bw())
library("sf")

library("rnaturalearth")
library("rnaturalearthdata")
library("colorspace")
library("scales")
# TASK Take the covid data from the last session and map the death / 
# cases over the time. Show the trend for the entire world as well as for Germany and the USA
#LINE PLOT

library(Quandl)
library(lubridate)
library(tidyverse)
library(readxl)
library(dplyr)
library(data.table)
url <- "https://opendata.ecdc.europa.eu/covid19/casedistribution/csv"
covid_data_dt <- fread(url)

class(covid_data_dt)

# Create a table with data we need
#First graph is for Cumulative Cases

covid_data_dt[,  `:=`(deaths_per_capita = deaths / popData2019,
                                          cases_per_capita = cases / popData2019,
                                          cases_per_deaths = cases / deaths)]

covid_data_dt[, cum_deaths := cumsum(deaths)]

covid_data_dt[, deaths_per_capita := (cum_deaths / popData2019)]

Relevant_data_needed<- covid_data_dt %>%
  
  # Select Columns
  select(dateRep, countriesAndTerritories, deaths_per_capita, countryterritoryCode) %>%
  group_by(countriesAndTerritories)%>%
  mutate(dateRep = as.Date(dateRep, "%d/%m/%Y")) %>%
  
  arrange(dateRep) 

Last_Data_date <- Relevant_data_needed %>%
  slice(which.max(dateRep))


Last_Data_date <- rename(Last_Data_date, adm0_a3 = countryterritoryCode )

world <- ne_countries(scale = "medium", returnclass = "sf")

World_updated <- merge(x = Last_Data_date, y = world, 
                       by    = "adm0_a3", 
                       all.x = TRUE, 
                       all.y = FALSE)

# 
# World_updated <- filter(World_updated, (cum_deaths_per_capita < 1) )

ggplot(data = World_updated) +
  geom_sf(aes(fill = deaths_per_capita, geometry = geometry)) +
  scale_fill_viridis_c(name = "Total Deaths Per Capita", 
                       option = "plasma", 
                       trans = "log", 
                       labels = comma)



```